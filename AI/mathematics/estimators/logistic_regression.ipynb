{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# LOGISTIC REGRESSION\n",
    "\n",
    "To delve deeper into logistic regression using a simple dataset with two observations, where each observation has two features and corresponding labels, let's construct a hypothetical example. We will follow this with an explanation of how logistic regression works with this dataset.\n",
    "\n",
    "### Hypothetical Dataset\n",
    "\n",
    "Consider a dataset with two observations, each with two features. Let's also assume we have binary labels for these observations, indicating two classes: 0 or 1.\n",
    "\n",
    "| $x_1$ | $x_2$ | $y$ |\n",
    "|-------|-------|-----|\n",
    "| 2     | 3     | 0   |\n",
    "| 4     | 1     | 1   |\n",
    "\n",
    "\n",
    "### Logistic Regression Overview\n",
    "\n",
    "Logistic regression aims to model the probability that a given input point belongs to a certain class. The probability of the outcome being in class '1' is modeled as a logistic function of a linear combination of the input features.\n",
    "\n",
    "### Model Representation\n",
    "\n",
    "The logistic model predicts the probability ($P$) that $Y=1$ for a given set of input features $X$. This is represented as:\n",
    "\n",
    "$P(Y=1|X) = \\frac{1}{1 + e^{-(\\theta_0 + \\theta_1 x_1 + \\theta_2 x_2)}}$\n",
    "\n",
    "Here, $\\theta_0$, $\\theta_1$, and $\\theta_2$ are the parameters of the model that we need to learn from the training data. $x_1$ and $x_2$ are the input features.\n",
    "\n",
    "### Learning Model Parameters\n",
    "\n",
    "The parameters $\\theta_0$, $\\theta_1$, and $\\theta_2$ are learned during the training process, where the model uses the known labels of the training data to adjust these parameters to predict the labels as accurately as possible. The learning process involves minimizing a cost function, typically using methods like gradient descent. The cost function for logistic regression is usually the binary cross-entropy, also known as the log loss.\n",
    "\n",
    "### Making Predictions\n",
    "\n",
    "Once the model parameters are learned, predictions for a new observation can be made by plugging the observation's features into the logistic model. If the predicted probability $P(Y=1|X)$ is greater than 0.5, the model predicts the class of the observation as '1'; otherwise, it predicts '0'.\n",
    "\n",
    "### Applying to Our Dataset\n",
    "\n",
    "Given our simple dataset, the logistic regression model will try to find the best $\\theta_0$, $\\theta_1$, and $\\theta_2$ values that lead to accurate predictions. For example, if the model learns parameters such that:\n",
    "\n",
    "- $\\theta_0$ = -1.5\n",
    "- $\\theta_1$ = 0.6\n",
    "- $\\theta_2$ = 0.4\n",
    "\n",
    "We can then calculate the probability of each observation being in class '1' using the logistic function.\n",
    "\n",
    "Let's perform these calculations to see how the model would predict the class for each observation based on the assumed parameters.\n",
    "\n",
    "For our hypothetical dataset, the logistic regression model with parameters $\\theta_0 = -1.5$, $\\theta_1 = 0.6$, and $\\theta_2 = 0.4$ predicts the probabilities of each observation being in class '1' as follows:\n",
    "\n",
    "- For Observation 1 (with features X₁ = 2, X₂ = 3), the predicted probability is approximately 0.711.\n",
    "- For Observation 2 (with features X₁ = 4, X₂ = 1), the predicted probability is approximately 0.786.\n",
    "\n",
    "Using a classification threshold of 0.5, where probabilities greater than or equal to 0.5 predict class '1' and probabilities less than 0.5 predict class '0', the model predicts both observations as belonging to class '1' (True indicates class '1').\n",
    "\n",
    "### Interpretation and Evaluation\n",
    "\n",
    "- **Observation 1**: Despite being labeled as class '0', the model predicts a high probability (0.711) of this observation belonging to class '1'. This indicates a misclassification based on our chosen threshold.\n",
    "- **Observation 2**: Correctly predicted as class '1', aligning with its actual label, with a high probability of 0.786.\n",
    "\n",
    "In a real-world scenario, logistic regression models are trained on larger datasets, allowing for more accurate parameter estimation and better generalization to unseen data. Model performance is typically evaluated using metrics like accuracy, precision, recall, and the ROC-AUC curve, which consider the model's predictions in relation to the actual labels across all observations.\n",
    "\n",
    "This simplified example serves to illustrate the mechanics of logistic regression, but keep in mind that real-world applications involve more complex datasets, parameter tuning, and validation techniques to ensure the model's effectiveness and robustness."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "977cd5087846821b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
