{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Decision function\n",
    "The decision function for a support vector classifier (SVC) can be derived from the linear equation that defines the \n",
    "hyperplane separating the two classes in the feature space. For a linear SVC, the decision function is given by:\n",
    "\n",
    "$f(\\mathbf{x}) = \\mathbf{w}^T \\mathbf{x} + b$\n",
    "\n",
    "Here:\n",
    "\n",
    "- $\\mathbf{w}$ is the weight vector (coefficients) of the hyperplane.\n",
    "- $\\mathbf{x}$ is the input feature vector.\n",
    "- $b$ is the bias term (intercept).\n",
    "\n",
    "The decision function outputs a real-valued number, which is the distance of the point $\\mathbf{x}$ from the hyperplane. The sign of the decision function determines the class label:\n",
    "\n",
    "- If $f(\\mathbf{x}) > 0$, the point is classified as belonging to the positive class.\n",
    "- If $f(\\mathbf{x}) < 0$, the point is classified as belonging to the negative class.\n",
    "- If $f(\\mathbf{x}) = 0$, the point lies exactly on the decision boundary (hyperplane)."
   ],
   "id": "d794e9476d91f8b1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Label transformation\n",
    "In Support Vector Classifiers (SVC), the labels of the classes are typically transformed to -1 and 1 to simplify the optimization problem. This transformation is particularly useful because it allows the classifier to express the decision boundary in a standardized way, leveraging the mathematical properties of these binary labels.\n",
    "\n",
    "### Transformation Formula\n",
    "\n",
    "Assume you have a dataset with binary class labels, typically denoted as 0 and 1. To transform these labels into -1 and 1 for use in a Support Vector Classifier, you can use the following formula:\n",
    "\n",
    "$\n",
    "y' = 2y - 1\n",
    "$\n",
    "\n",
    "Where:\n",
    "- $y$ is the original label, either 0 or 1.\n",
    "- $y'$ is the transformed label, either -1 or 1.\n",
    "\n",
    "### Example\n",
    "\n",
    "If $y = 0$:\n",
    "$\n",
    "y' = 2(0) - 1 = -1\n",
    "$\n",
    "\n",
    "If $y = 1$:\n",
    "$\n",
    "y' = 2(1) - 1 = 1\n",
    "$\n",
    "\n",
    "### Why This Transformation?\n",
    "\n",
    "The transformation to -1 and 1 is advantageous in the context of SVC because:\n",
    "\n",
    "1. **Simplifies the Optimization Problem**: The optimization problem in SVMs involves maximizing the margin between the classes. With labels -1 and 1, the margin can be directly related to the distance from the decision boundary, which is expressed as $f(\\mathbf{x}) = \\mathbf{w}^T \\mathbf{x} + b$. This simplifies the constraints to $y' \\cdot f(\\mathbf{x}) \\geq 1$.\n",
    "\n",
    "2. **Mathematical Properties**: The transformation leverages the algebraic properties of these labels in dot products and other operations during the optimization process, leading to more straightforward and efficient computations.\n",
    "\n",
    "This transformation is standard practice in the implementation of binary SVMs. For multi-class SVMs, similar principles apply, but the transformation and decision process involve handling multiple binary classifiers."
   ],
   "id": "4b311d90f14bd8bb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T13:43:15.602761Z",
     "start_time": "2024-08-24T13:43:15.600466Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "26e5b29b5b513d6f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
